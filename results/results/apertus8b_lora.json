{
  "config_general": {
    "lighteval_sha": "?",
    "num_fewshot_seeds": 1,
    "max_samples": null,
    "job_id": "0",
    "start_time": 1326631.736748796,
    "end_time": 1327920.374229118,
    "total_evaluation_time_secondes": "1288.6374803220388",
    "model_config": {
      "model_name": "/users/jmirlach/scratch/apertus-finetuning-lsai/evaluation/merged_model",
      "generation_parameters": {
        "num_blocks": null,
        "block_size": null,
        "early_stopping": null,
        "repetition_penalty": 1.05,
        "frequency_penalty": null,
        "length_penalty": null,
        "presence_penalty": null,
        "max_new_tokens": null,
        "min_new_tokens": null,
        "seed": 2025,
        "stop_tokens": null,
        "temperature": 0.7,
        "top_k": 20,
        "min_p": null,
        "top_p": 0.8,
        "truncate_prompt": null,
        "cache_implementation": null,
        "response_format": null
      },
      "system_prompt": "You are a legal expert specializing in Swiss Federal Supreme Court decisions with extensive knowledge of legal terminology and conventions in German, French, and Italian. Your task is to generate a headnote for a provided leading decision. A headnote is a concise summary that captures the key legal points and significance of the decision. It is not merely a summary of the content but highlights the aspects that make the decision \"leading\" and important for future legislation.\n\nWhen generating the headnote:\n\n1. Focus on the core legal reasoning and key considerations that establish the decision's significance.\n2. Include any relevant references to legal articles (prefixed with \"Art.\") and considerations (prefixed with \"E.\" in German or \"consid.\" in French/Italian).\n3. Use precise legal terminology and adhere to the formal and professional style typical of Swiss Federal Supreme Court headnotes.\n4. Ensure clarity and coherence, so the headnote is logically structured and easy to understand in the specified language.\n\nYour response should consist solely of the headnote in the language specified by the user prompt.",
      "cache_dir": "~/.cache/huggingface/lighteval",
      "tokenizer": null,
      "revision": "main",
      "dtype": "bfloat16",
      "tensor_parallel_size": 4,
      "data_parallel_size": 1,
      "pipeline_parallel_size": 1,
      "gpu_memory_utilization": 0.7,
      "enable_prefix_caching": false,
      "max_model_length": 8192,
      "quantization": null,
      "load_format": null,
      "swap_space": 8,
      "seed": 2025,
      "trust_remote_code": true,
      "add_special_tokens": true,
      "multichoice_continuations_start_space": true,
      "pairwise_tokenization": false,
      "max_num_seqs": 64,
      "max_num_batched_tokens": 2048,
      "subfolder": null,
      "is_async": false,
      "override_chat_template": null
    },
    "model_name": "/users/jmirlach/scratch/apertus-finetuning-lsai/evaluation/merged_model"
  },
  "results": {
    "slds:fr_it|0": {
      "slds_judge": 22.61682242990654,
      "slds_judge_stderr": 1.6709391176201933,
      "BERTScore-P": 36.300774867359166,
      "BERTScore-P_stderr": 1.505070213010312,
      "BERTScore-R": 25.396254290957177,
      "BERTScore-R_stderr": 1.3172553697164353,
      "BERTScore-F": 30.843744809939484,
      "BERTScore-F_stderr": 1.0542225077365357,
      "bleu": 11.26476823401815,
      "bleu_stderr": 0.027049424873597534,
      "rouge1": 0.35514772749000817,
      "rouge1_stderr": 0.009062994011440133,
      "rouge2": 0.1484832021790085,
      "rouge2_stderr": 0.007297865264390321,
      "rougeL": 0.2342786754944297,
      "rougeL_stderr": 0.006727678749632362,
      "summarization_coverage": 0.3545957911411612,
      "summarization_coverage_stderr": 0.007470704271909029,
      "summarization_density": 0.6104323683689491,
      "summarization_density_stderr": 0.01938859657250251,
      "summarization_compression": 52.54741077455627,
      "summarization_compression_stderr": 3.441222965334687
    },
    "slds:fr_de|0": {
      "slds_judge": 25.514018691588785,
      "slds_judge_stderr": 1.7876792069383272,
      "BERTScore-P": 22.31422162062062,
      "BERTScore-P_stderr": 2.1054390227250632,
      "BERTScore-R": 8.173127243051601,
      "BERTScore-R_stderr": 1.7259861635056208,
      "BERTScore-F": 15.228637311363888,
      "BERTScore-F_stderr": 1.5111634978977966,
      "bleu": 10.100365800959002,
      "bleu_stderr": 0.024965054715962495,
      "rouge1": 0.3035450561539835,
      "rouge1_stderr": 0.008155420231605984,
      "rouge2": 0.11153813522682621,
      "rouge2_stderr": 0.00572977710580324,
      "rougeL": 0.20540394779484977,
      "rougeL_stderr": 0.006479102093665761,
      "summarization_coverage": 0.3975443072352518,
      "summarization_coverage_stderr": 0.013687617233443956,
      "summarization_density": 1.7575332998670756,
      "summarization_density_stderr": 0.8084749968096848,
      "summarization_compression": 58.27340571081508,
      "summarization_compression_stderr": 3.7367563960999393
    },
    "slds:it_de|0": {
      "slds_judge": 13.333333333333334,
      "slds_judge_stderr": 3.097734590948617,
      "BERTScore-P": 12.800276589890322,
      "BERTScore-P_stderr": 8.516317235083754,
      "BERTScore-R": 3.2721757500742874,
      "BERTScore-R_stderr": 3.911440002278615,
      "BERTScore-F": 7.993116579018533,
      "BERTScore-F_stderr": 3.6099257035384107,
      "bleu": 9.744348493459654,
      "bleu_stderr": 0.0524628810064694,
      "rouge1": 0.2634121038461461,
      "rouge1_stderr": 0.0274212307076749,
      "rouge2": 0.09924629517469241,
      "rouge2_stderr": 0.015536184376956749,
      "rougeL": 0.17142031353868512,
      "rougeL_stderr": 0.01772935556856192,
      "summarization_coverage": 0.41034782873996084,
      "summarization_coverage_stderr": 0.02875935591681038,
      "summarization_density": 0.6857501351672206,
      "summarization_density_stderr": 0.05060090925508573,
      "summarization_compression": 55.20706135634976,
      "summarization_compression_stderr": 10.025448367611627
    },
    "slds:de_de|0": {
      "slds_judge": 29.17874396135266,
      "slds_judge_stderr": 1.280876674740373,
      "BERTScore-P": 33.05922227074811,
      "BERTScore-P_stderr": 1.6659731688016661,
      "BERTScore-R": 17.986342319351895,
      "BERTScore-R_stderr": 1.3470282632912007,
      "BERTScore-F": 25.497466799519632,
      "BERTScore-F_stderr": 1.1835484502639344,
      "bleu": 14.75222351872232,
      "bleu_stderr": 0.024261773774770182,
      "rouge1": 0.3573912424414005,
      "rouge1_stderr": 0.008279841966600457,
      "rouge2": 0.17569543622015885,
      "rouge2_stderr": 0.007195458016374032,
      "rougeL": 0.2595702508284258,
      "rougeL_stderr": 0.007060163348301771,
      "summarization_coverage": 0.9371517992826668,
      "summarization_coverage_stderr": 0.0037277793573226204,
      "summarization_density": 7.693334859256831,
      "summarization_density_stderr": 0.6392190093946974,
      "summarization_compression": 52.89987024919478,
      "summarization_compression_stderr": 2.92071916553605
    },
    "slds:it_it|0": {
      "slds_judge": 22.5,
      "slds_judge_stderr": 3.9167472590032015,
      "BERTScore-P": 31.201848822335403,
      "BERTScore-P_stderr": 5.605704337018306,
      "BERTScore-R": 25.204663110586505,
      "BERTScore-R_stderr": 5.947370156238972,
      "BERTScore-F": 28.183085347215336,
      "BERTScore-F_stderr": 4.101546248968306,
      "bleu": 12.93760475967064,
      "bleu_stderr": 0.08978720133307466,
      "rouge1": 0.35455521808197527,
      "rouge1_stderr": 0.030673813260193653,
      "rouge2": 0.16827350413516132,
      "rouge2_stderr": 0.026578686444207026,
      "rougeL": 0.22894988283933637,
      "rougeL_stderr": 0.021381308863326568,
      "summarization_coverage": 0.9548766894959523,
      "summarization_coverage_stderr": 0.010000452044378301,
      "summarization_density": 14.178885301599728,
      "summarization_density_stderr": 5.223667784593835,
      "summarization_compression": 53.26893209457265,
      "summarization_compression_stderr": 11.221020993459305
    },
    "slds:fr_fr|0": {
      "slds_judge": 32.89719626168224,
      "slds_judge_stderr": 2.065790353965008,
      "BERTScore-P": 41.24808482059809,
      "BERTScore-P_stderr": 1.81809996494116,
      "BERTScore-R": 27.88652796341785,
      "BERTScore-R_stderr": 1.6742982948914689,
      "BERTScore-F": 34.55290688532535,
      "BERTScore-F_stderr": 1.3758420381363932,
      "bleu": 16.313538850267182,
      "bleu_stderr": 0.042120501293260844,
      "rouge1": 0.4251108632524486,
      "rouge1_stderr": 0.011678525719925732,
      "rouge2": 0.22633494523205022,
      "rouge2_stderr": 0.011132829962401076,
      "rougeL": 0.2885130609707884,
      "rougeL_stderr": 0.00963352906495338,
      "summarization_coverage": 0.9594638798629574,
      "summarization_coverage_stderr": 0.004334566339598788,
      "summarization_density": 11.681664543211125,
      "summarization_density_stderr": 1.3702715913881411,
      "summarization_compression": 53.65673997105416,
      "summarization_compression_stderr": 4.618930019968573
    },
    "slds:it_fr|0": {
      "slds_judge": 32.5,
      "slds_judge_stderr": 5.78988145584409,
      "BERTScore-P": 29.705968002478283,
      "BERTScore-P_stderr": 7.663203701677307,
      "BERTScore-R": 23.291600464532774,
      "BERTScore-R_stderr": 5.068313187710188,
      "BERTScore-F": 26.461239873121183,
      "BERTScore-F_stderr": 4.222942285886393,
      "bleu": 12.038593134860553,
      "bleu_stderr": 0.0799156068073335,
      "rouge1": 0.3546277882802216,
      "rouge1_stderr": 0.03921871197564934,
      "rouge2": 0.160341141211941,
      "rouge2_stderr": 0.023728594784001994,
      "rougeL": 0.2248391410883319,
      "rougeL_stderr": 0.023780748744397624,
      "summarization_coverage": 0.5104272819494372,
      "summarization_coverage_stderr": 0.035737889225575095,
      "summarization_density": 1.0803309262637855,
      "summarization_density_stderr": 0.1499341727448119,
      "summarization_compression": 53.76804845419059,
      "summarization_compression_stderr": 10.732608552419979
    },
    "slds:de_it|0": {
      "slds_judge": 16.47342995169082,
      "slds_judge_stderr": 1.161480198782138,
      "BERTScore-P": 32.99926201012075,
      "BERTScore-P_stderr": 1.1118890594886812,
      "BERTScore-R": 22.652941313684707,
      "BERTScore-R_stderr": 1.26433434403334,
      "BERTScore-F": 27.8255226234523,
      "BERTScore-F_stderr": 1.0060205673845752,
      "bleu": 11.204350352877936,
      "bleu_stderr": 0.014600930982952115,
      "rouge1": 0.3332049955242157,
      "rouge1_stderr": 0.006251835711650228,
      "rouge2": 0.12856027988101704,
      "rouge2_stderr": 0.004248392309726283,
      "rougeL": 0.22158018890419182,
      "rougeL_stderr": 0.004592360589466047,
      "summarization_coverage": 0.309527349273122,
      "summarization_coverage_stderr": 0.006836108523982483,
      "summarization_density": 0.5004469005908777,
      "summarization_density_stderr": 0.01672386056752633,
      "summarization_compression": 41.34616475390417,
      "summarization_compression_stderr": 2.470488062786647
    },
    "slds:de_fr|0": {
      "slds_judge": 26.76328502415459,
      "slds_judge_stderr": 1.4294486722324622,
      "BERTScore-P": 33.38734201742741,
      "BERTScore-P_stderr": 1.2870579876035213,
      "BERTScore-R": 23.31036801195753,
      "BERTScore-R_stderr": 1.4628922712688897,
      "BERTScore-F": 28.345696121883908,
      "BERTScore-F_stderr": 1.1926835127445152,
      "bleu": 12.31934772434781,
      "bleu_stderr": 0.017127012615524552,
      "rouge1": 0.38554509217150024,
      "rouge1_stderr": 0.007600395562000104,
      "rouge2": 0.16140563982853876,
      "rouge2_stderr": 0.005351529339820005,
      "rougeL": 0.24727328117642397,
      "rougeL_stderr": 0.005692643097514295,
      "summarization_coverage": 0.36365983234897276,
      "summarization_coverage_stderr": 0.008917256160378924,
      "summarization_density": 0.6911409868728609,
      "summarization_density_stderr": 0.024039580830952905,
      "summarization_compression": 36.67362042136505,
      "summarization_compression_stderr": 1.8793984250630151
    },
    "slds:_average|0": {
      "slds_judge": 24.64186996152322,
      "slds_judge_stderr": 2.4667308366749348,
      "BERTScore-P": 30.335222335730904,
      "BERTScore-P_stderr": 3.475417187816641,
      "BERTScore-R": 19.686000051957148,
      "BERTScore-R_stderr": 2.63543533921497,
      "BERTScore-F": 24.992379594537734,
      "BERTScore-F_stderr": 2.1397660902840956,
      "bleu": 12.297237874353694,
      "bleu_stderr": 0.04136559860032726,
      "rouge1": 0.34806000969354445,
      "rouge1_stderr": 0.01648252990519339,
      "rouge2": 0.15331984212104383,
      "rouge2_stderr": 0.011866590844853413,
      "rougeL": 0.23131430473727363,
      "rougeL_stderr": 0.011452987791091081,
      "summarization_coverage": 0.5775105288143869,
      "summarization_coverage_stderr": 0.013274636563711063,
      "summarization_density": 4.319946591244272,
      "summarization_density_stderr": 0.9224800557952487,
      "summarization_compression": 50.84902819844472,
      "summarization_compression_stderr": 5.67184366091998
    },
    "all": {
      "slds_judge": 24.64186996152322,
      "slds_judge_stderr": 2.4667308366749343,
      "BERTScore-P": 30.335222335730904,
      "BERTScore-P_stderr": 3.475417187816641,
      "BERTScore-R": 19.686000051957148,
      "BERTScore-R_stderr": 2.63543533921497,
      "BERTScore-F": 24.992379594537738,
      "BERTScore-F_stderr": 2.1397660902840956,
      "bleu": 12.297237874353693,
      "bleu_stderr": 0.041365598600327264,
      "rouge1": 0.34806000969354445,
      "rouge1_stderr": 0.016482529905193388,
      "rouge2": 0.15331984212104383,
      "rouge2_stderr": 0.011866590844853413,
      "rougeL": 0.23131430473727363,
      "rougeL_stderr": 0.011452987791091083,
      "summarization_coverage": 0.5775105288143869,
      "summarization_coverage_stderr": 0.013274636563711065,
      "summarization_density": 4.319946591244272,
      "summarization_density_stderr": 0.9224800557952487,
      "summarization_compression": 50.84902819844472,
      "summarization_compression_stderr": 5.671843660919981
    }
  },
  "versions": {},
  "config_tasks": {
    "slds:fr_it|0": {
      "name": "slds:fr_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x40064b03bd10>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40064b6165a0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40064ae0ca70>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40064b038bc0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40064b03a870>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:fr_de|0": {
      "name": "slds:fr_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4004d751fec0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d4504f50>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d458d100>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d751fbf0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4004d751fd40>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:it_de|0": {
      "name": "slds:it_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x400653f598e0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d4507620>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4006577bd100>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400653f59730>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x400653f59b50>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:de_de|0": {
      "name": "slds:de_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x40065f9c94f0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40065fed4d10>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40065ff7df40>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40065ff7c260>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40065f9c95e0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:it_it|0": {
      "name": "slds:it_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4007ec031c70>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007ec0fe060>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007ec0cd100>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007ec031af0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4007ec031b50>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:fr_fr|0": {
      "name": "slds:fr_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4007ec9dec60>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007ec9dede0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007ec9dc260>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007ec9ded80>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4007ec9dee40>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:it_fr|0": {
      "name": "slds:it_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4007ec95be30>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007ec95ba70>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007ec95bf50>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40054e7ba6c0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40054e7a77d0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:de_it|0": {
      "name": "slds:de_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4007f3c885f0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007f3c89790>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007f3c895e0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007f3c88500>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4007f3c883e0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:de_fr|0": {
      "name": "slds:de_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4005089cf230>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4005089cf4d0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4005089cf500>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4005089cf440>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4005089cf0b0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    }
  },
  "summary_tasks": {
    "slds:fr_it|0": {
      "hashes": {
        "hash_examples": "ca4af939c99421ed",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "7fd9b8323b529819",
        "hash_cont_tokens": "17b23db91018278e"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_de|0": {
      "hashes": {
        "hash_examples": "82f729c52bea2d22",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "6ee5c1b121690d00",
        "hash_cont_tokens": "9a9612fa209ce264"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:it_de|0": {
      "hashes": {
        "hash_examples": "aa127a747078d118",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "f98ac6770246028c",
        "hash_cont_tokens": "0edb3f355735ebf4"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_de|0": {
      "hashes": {
        "hash_examples": "5712a1f521ca0984",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "4b31c3347666af64",
        "hash_cont_tokens": "90d47a61bcd3cdc0"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:it_it|0": {
      "hashes": {
        "hash_examples": "1283225273f183c5",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "b386ca226c5c7c6f",
        "hash_cont_tokens": "0c37caf9582a4bff"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_fr|0": {
      "hashes": {
        "hash_examples": "df93c7b6eee9775c",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "615da813a6431415",
        "hash_cont_tokens": "7f10857ed963089c"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:it_fr|0": {
      "hashes": {
        "hash_examples": "738c01fc1ccddbab",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "005710cb28947926",
        "hash_cont_tokens": "c38fd2040095dd39"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_it|0": {
      "hashes": {
        "hash_examples": "8ae552be61473db8",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "d4f7bfe5fb38b628",
        "hash_cont_tokens": "b10132ff72b3700b"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_fr|0": {
      "hashes": {
        "hash_examples": "2789212d8ee281ea",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "ab8d9d65c56f2f62",
        "hash_cont_tokens": "5d230fd84c50175a"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    }
  },
  "summary_general": {
    "hashes": {
      "hash_examples": "e31e497cb001a9c8",
      "hash_full_prompts": "36ab1e8e1061f5c1",
      "hash_input_tokens": "9d2692393928fc22",
      "hash_cont_tokens": "028f5d8014024a2c"
    },
    "truncated": 0,
    "non_truncated": 0,
    "padded": 0,
    "non_padded": 0
  }
}