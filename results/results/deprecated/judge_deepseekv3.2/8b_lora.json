{
  "config_general": {
    "lighteval_sha": "?",
    "num_fewshot_seeds": 1,
    "max_samples": null,
    "job_id": "0",
    "start_time": 527031.08672784,
    "end_time": 532256.286456153,
    "total_evaluation_time_secondes": "5225.199728313019",
    "model_config": {
      "model_name": "/users/jmirlach/scratch/apertus-finetuning-lsai/evaluation/merged_model",
      "generation_parameters": {
        "num_blocks": null,
        "block_size": null,
        "early_stopping": null,
        "repetition_penalty": 1.05,
        "frequency_penalty": null,
        "length_penalty": null,
        "presence_penalty": null,
        "max_new_tokens": null,
        "min_new_tokens": null,
        "seed": 2025,
        "stop_tokens": null,
        "temperature": 0.7,
        "top_k": 20,
        "min_p": null,
        "top_p": 0.8,
        "truncate_prompt": null,
        "cache_implementation": null,
        "response_format": null
      },
      "system_prompt": "You are a legal expert specializing in Swiss Federal Supreme Court decisions with extensive knowledge of legal terminology and conventions in German, French, and Italian. Your task is to generate a headnote for a provided leading decision. A headnote is a concise summary that captures the key legal points and significance of the decision. It is not merely a summary of the content but highlights the aspects that make the decision \"leading\" and important for future legislation.\n\nWhen generating the headnote:\n\n1. Focus on the core legal reasoning and key considerations that establish the decision's significance.\n2. Include any relevant references to legal articles (prefixed with \"Art.\") and considerations (prefixed with \"E.\" in German or \"consid.\" in French/Italian).\n3. Use precise legal terminology and adhere to the formal and professional style typical of Swiss Federal Supreme Court headnotes.\n4. Ensure clarity and coherence, so the headnote is logically structured and easy to understand in the specified language.\n\nYour response should consist solely of the headnote in the language specified by the user prompt.",
      "cache_dir": "~/.cache/huggingface/lighteval",
      "tokenizer": null,
      "revision": "main",
      "dtype": "bfloat16",
      "tensor_parallel_size": 4,
      "data_parallel_size": 1,
      "pipeline_parallel_size": 1,
      "gpu_memory_utilization": 0.7,
      "enable_prefix_caching": false,
      "max_model_length": 8192,
      "quantization": null,
      "load_format": null,
      "swap_space": 8,
      "seed": 2025,
      "trust_remote_code": true,
      "add_special_tokens": true,
      "multichoice_continuations_start_space": true,
      "pairwise_tokenization": false,
      "max_num_seqs": 64,
      "max_num_batched_tokens": 2048,
      "subfolder": null,
      "is_async": false,
      "override_chat_template": null
    },
    "model_name": "/users/jmirlach/scratch/apertus-finetuning-lsai/evaluation/merged_model"
  },
  "results": {
    "slds:it_fr|0": {
      "slds_judge": 24.166666666666668,
      "slds_judge_stderr": 4.344682108769597,
      "BERTScore-P": 24.878145894035697,
      "BERTScore-P_stderr": 6.613280757806231,
      "BERTScore-R": 20.668999361805618,
      "BERTScore-R_stderr": 5.524814238303326,
      "BERTScore-F": 22.749855120976765,
      "BERTScore-F_stderr": 4.169874261505369,
      "bleu": 10.414301739344303,
      "bleu_stderr": 0.067857064776676,
      "rouge1": 0.3351514524383527,
      "rouge1_stderr": 0.03815241111443656,
      "rouge2": 0.14019237686559916,
      "rouge2_stderr": 0.024655827453380134,
      "rougeL": 0.20380177277755762,
      "rougeL_stderr": 0.019218604988264096,
      "summarization_coverage": 0.49279567301340704,
      "summarization_coverage_stderr": 0.04249665585378298,
      "summarization_density": 1.106830508922468,
      "summarization_density_stderr": 0.18239656546119376,
      "summarization_compression": 54.787261815614606,
      "summarization_compression_stderr": 15.925468064545594
    },
    "slds:fr_de|0": {
      "slds_judge": 14.766355140186915,
      "slds_judge_stderr": 1.4807635893301354,
      "BERTScore-P": 23.63344503177121,
      "BERTScore-P_stderr": 2.1426413954310215,
      "BERTScore-R": 10.169661438928168,
      "BERTScore-R_stderr": 1.6925975353715328,
      "BERTScore-F": 16.885233554057777,
      "BERTScore-F_stderr": 1.488367367254382,
      "bleu": 11.811100520722185,
      "bleu_stderr": 0.02417528993439021,
      "rouge1": 0.32249732947069676,
      "rouge1_stderr": 0.007792218939907691,
      "rouge2": 0.12291178696424887,
      "rouge2_stderr": 0.0065345089413166805,
      "rougeL": 0.21639249308282277,
      "rougeL_stderr": 0.00601325746780008,
      "summarization_coverage": 0.3937982884311696,
      "summarization_coverage_stderr": 0.01312919036222576,
      "summarization_density": 1.5695603674258956,
      "summarization_density_stderr": 0.7859224240879885,
      "summarization_compression": 55.69124288143488,
      "summarization_compression_stderr": 3.7503184829104486
    },
    "slds:it_de|0": {
      "slds_judge": 7.5,
      "slds_judge_stderr": 3.2856437033638546,
      "BERTScore-P": 17.168051066497963,
      "BERTScore-P_stderr": 8.016157260567361,
      "BERTScore-R": 4.6122762296969695,
      "BERTScore-R_stderr": 5.7946006649441,
      "BERTScore-F": 10.849809615562359,
      "BERTScore-F_stderr": 4.626010494468877,
      "bleu": 9.57227245075103,
      "bleu_stderr": 0.06333409534444097,
      "rouge1": 0.2881695989514116,
      "rouge1_stderr": 0.03387573043397299,
      "rouge2": 0.10937821192406076,
      "rouge2_stderr": 0.021512301382579882,
      "rougeL": 0.18334452522494382,
      "rougeL_stderr": 0.020743822459429153,
      "summarization_coverage": 0.40096098576922484,
      "summarization_coverage_stderr": 0.034390020608473536,
      "summarization_density": 0.7311664828194577,
      "summarization_density_stderr": 0.09160107396604346,
      "summarization_compression": 54.53097292886087,
      "summarization_compression_stderr": 8.56586167389521
    },
    "slds:fr_fr|0": {
      "slds_judge": 24.018691588785046,
      "slds_judge_stderr": 2.0393752828797735,
      "BERTScore-P": 43.88249806111035,
      "BERTScore-P_stderr": 1.68357037675377,
      "BERTScore-R": 27.893729262906955,
      "BERTScore-R_stderr": 1.6470938656581142,
      "BERTScore-F": 35.87197634330559,
      "BERTScore-F_stderr": 1.3122094294365012,
      "bleu": 15.40925886558152,
      "bleu_stderr": 0.0365598912243876,
      "rouge1": 0.4241546201865786,
      "rouge1_stderr": 0.01123752778248921,
      "rouge2": 0.22635649620194476,
      "rouge2_stderr": 0.010579015019803165,
      "rougeL": 0.2849365536854395,
      "rougeL_stderr": 0.009373086572611513,
      "summarization_coverage": 0.9668880633156317,
      "summarization_coverage_stderr": 0.003408808647578707,
      "summarization_density": 15.721088323546184,
      "summarization_density_stderr": 2.5429900867383233,
      "summarization_compression": 56.62443106203248,
      "summarization_compression_stderr": 4.603223830319524
    },
    "slds:fr_it|0": {
      "slds_judge": 15.88785046728972,
      "slds_judge_stderr": 1.454374408555664,
      "BERTScore-P": 34.94963114471915,
      "BERTScore-P_stderr": 1.4710568538413369,
      "BERTScore-R": 24.247936953172506,
      "BERTScore-R_stderr": 1.3683790497338773,
      "BERTScore-F": 29.596501505263497,
      "BERTScore-F_stderr": 1.0960665581975932,
      "bleu": 10.433413180180452,
      "bleu_stderr": 0.022697334100421344,
      "rouge1": 0.3473583452972955,
      "rouge1_stderr": 0.008808653229146972,
      "rouge2": 0.13946945331730698,
      "rouge2_stderr": 0.007173400875171053,
      "rougeL": 0.22750010842217877,
      "rougeL_stderr": 0.006495121527387428,
      "summarization_coverage": 0.3547256125496574,
      "summarization_coverage_stderr": 0.007353361282554627,
      "summarization_density": 0.6330370981015238,
      "summarization_density_stderr": 0.03708605659730816,
      "summarization_compression": 52.29780276598337,
      "summarization_compression_stderr": 3.5195252926870757
    },
    "slds:it_it|0": {
      "slds_judge": 19.166666666666668,
      "slds_judge_stderr": 5.1431527492405085,
      "BERTScore-P": 35.99676207328836,
      "BERTScore-P_stderr": 5.9160663286198005,
      "BERTScore-R": 25.017713631192844,
      "BERTScore-R_stderr": 4.870484457468746,
      "BERTScore-F": 30.4855818549792,
      "BERTScore-F_stderr": 3.7942116401420485,
      "bleu": 12.28340508051082,
      "bleu_stderr": 0.09805859195731399,
      "rouge1": 0.36177641761162577,
      "rouge1_stderr": 0.0363260886323463,
      "rouge2": 0.1919373115292449,
      "rouge2_stderr": 0.03796849659512341,
      "rougeL": 0.24799944264344695,
      "rougeL_stderr": 0.021682776090745825,
      "summarization_coverage": 0.9523128629683857,
      "summarization_coverage_stderr": 0.009301172647129366,
      "summarization_density": 9.36776350370863,
      "summarization_density_stderr": 1.9111094207046397,
      "summarization_compression": 59.46779293467153,
      "summarization_compression_stderr": 11.522685186797696
    },
    "slds:de_de|0": {
      "slds_judge": 18.88888888888889,
      "slds_judge_stderr": 1.2594974259104552,
      "BERTScore-P": 32.95323239157993,
      "BERTScore-P_stderr": 1.6623567179819532,
      "BERTScore-R": 17.138812185663298,
      "BERTScore-R_stderr": 1.3833856551172026,
      "BERTScore-F": 25.022683341443035,
      "BERTScore-F_stderr": 1.2341097426111325,
      "bleu": 14.0854356489527,
      "bleu_stderr": 0.023710582450564156,
      "rouge1": 0.3525570903494334,
      "rouge1_stderr": 0.00844574818277344,
      "rouge2": 0.17338234354803334,
      "rouge2_stderr": 0.007332161380219472,
      "rougeL": 0.2607467420323837,
      "rougeL_stderr": 0.0072418109030393295,
      "summarization_coverage": 0.9377035965620377,
      "summarization_coverage_stderr": 0.004218763785985742,
      "summarization_density": 8.35881485127676,
      "summarization_density_stderr": 0.751707379198586,
      "summarization_compression": 54.921746990162895,
      "summarization_compression_stderr": 3.1328672130977777
    },
    "slds:de_it|0": {
      "slds_judge": 13.333333333333334,
      "slds_judge_stderr": 0.9162684451669434,
      "BERTScore-P": 34.130705052712294,
      "BERTScore-P_stderr": 1.0745232958955826,
      "BERTScore-R": 22.447316260369504,
      "BERTScore-R_stderr": 1.2481503655464425,
      "BERTScore-F": 28.28695829912732,
      "BERTScore-F_stderr": 0.9789063982167251,
      "bleu": 11.415599715837544,
      "bleu_stderr": 0.01604475205777804,
      "rouge1": 0.33669770992419445,
      "rouge1_stderr": 0.0063418717740692096,
      "rouge2": 0.1299662043333093,
      "rouge2_stderr": 0.004572427746619215,
      "rougeL": 0.2241765366404892,
      "rougeL_stderr": 0.004908044716891734,
      "summarization_coverage": 0.3165637382158813,
      "summarization_coverage_stderr": 0.00784456014216693,
      "summarization_density": 0.5065603546204905,
      "summarization_density_stderr": 0.014511405557683635,
      "summarization_compression": 41.98515930330569,
      "summarization_compression_stderr": 2.4748270167146638
    },
    "slds:de_fr|0": {
      "slds_judge": 18.93719806763285,
      "slds_judge_stderr": 1.2754255640642385,
      "BERTScore-P": 34.391590906981975,
      "BERTScore-P_stderr": 1.2326476377184983,
      "BERTScore-R": 23.714211839082502,
      "BERTScore-R_stderr": 1.2586387258977336,
      "BERTScore-F": 29.047697991726622,
      "BERTScore-F_stderr": 1.0233508116133148,
      "bleu": 12.488620290464377,
      "bleu_stderr": 0.016211221785826617,
      "rouge1": 0.38082029153352953,
      "rouge1_stderr": 0.007505402047614427,
      "rouge2": 0.15843157926430845,
      "rouge2_stderr": 0.005395837252322857,
      "rougeL": 0.2453235098951347,
      "rougeL_stderr": 0.005712165616077204,
      "summarization_coverage": 0.36974055849657994,
      "summarization_coverage_stderr": 0.008734135465274979,
      "summarization_density": 0.7035391945569673,
      "summarization_density_stderr": 0.02413555201617234,
      "summarization_compression": 36.89004806775295,
      "summarization_compression_stderr": 2.012014551704609
    },
    "slds:_average|0": {
      "slds_judge": 17.407294535494454,
      "slds_judge_stderr": 2.3554648085867966,
      "BERTScore-P": 31.33156240252188,
      "BERTScore-P_stderr": 3.3124778471795064,
      "BERTScore-R": 19.545628573646482,
      "BERTScore-R_stderr": 2.754238284226786,
      "BERTScore-F": 25.421810847382464,
      "BERTScore-F_stderr": 2.1914563003828826,
      "bleu": 11.990378610260548,
      "bleu_stderr": 0.040960980403533215,
      "rouge1": 0.34990920619590204,
      "rouge1_stderr": 0.01760951690408409,
      "rouge2": 0.15466952932756184,
      "rouge2_stderr": 0.013969330738503986,
      "rougeL": 0.2326912982671552,
      "rougeL_stderr": 0.011265410038027373,
      "summarization_coverage": 0.5761654865913306,
      "summarization_coverage_stderr": 0.014541852088352514,
      "summarization_density": 4.299817853886486,
      "summarization_density_stderr": 0.7046066627031043,
      "summarization_compression": 51.91071763886881,
      "summarization_compression_stderr": 6.167421256963622
    },
    "all": {
      "slds_judge": 17.407294535494454,
      "slds_judge_stderr": 2.355464808586797,
      "BERTScore-P": 31.33156240252188,
      "BERTScore-P_stderr": 3.312477847179506,
      "BERTScore-R": 19.545628573646486,
      "BERTScore-R_stderr": 2.7542382842267856,
      "BERTScore-F": 25.42181084738246,
      "BERTScore-F_stderr": 2.191456300382883,
      "bleu": 11.990378610260548,
      "bleu_stderr": 0.040960980403533215,
      "rouge1": 0.34990920619590204,
      "rouge1_stderr": 0.017609516904084088,
      "rouge2": 0.15466952932756184,
      "rouge2_stderr": 0.013969330738503986,
      "rougeL": 0.2326912982671552,
      "rougeL_stderr": 0.011265410038027375,
      "summarization_coverage": 0.5761654865913306,
      "summarization_coverage_stderr": 0.014541852088352514,
      "summarization_density": 4.299817853886486,
      "summarization_density_stderr": 0.7046066627031045,
      "summarization_compression": 51.91071763886881,
      "summarization_compression_stderr": 6.167421256963622
    }
  },
  "versions": {},
  "config_tasks": {
    "slds:it_fr|0": {
      "name": "slds:it_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x400628bd2b70>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400628bd1820>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400628bd0260>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400628bd0920>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40021174eb40>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:fr_de|0": {
      "name": "slds:fr_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4006288e88c0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4002117517f0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004e6e55280>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4001f7a12600>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4001f7a12630>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:it_de|0": {
      "name": "slds:it_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x400631d37110>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400631d37260>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400631d37290>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400631d37380>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x400631d34170>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:fr_fr|0": {
      "name": "slds:fr_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x40063bad7e00>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40063b9f81a0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40063bad7c50>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40063bad7c80>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40063bad7fe0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:fr_it|0": {
      "name": "slds:fr_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4007c7a3fe60>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007c7a3fc20>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007c7a3fda0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007c7a3fbf0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4007c7a3fc80>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:it_it|0": {
      "name": "slds:it_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4007c94c3fb0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400628b03fe0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007c94842c0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007c9484260>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4007c9484170>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:de_de|0": {
      "name": "slds:de_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4007cb2f9490>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007cb2f95e0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007cb2f9640>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007cb2f9580>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4007cb32a720>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:de_it|0": {
      "name": "slds:de_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4007d8575a60>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007d8575bb0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007d8575be0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007d8575b50>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4007d8575c40>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    },
    "slds:de_fr|0": {
      "name": "slds:de_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4007db433620>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007db4337d0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007db4337a0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4007db433770>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4007db433500>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 0,
      "version": 0
    }
  },
  "summary_tasks": {
    "slds:it_fr|0": {
      "hashes": {
        "hash_examples": "738c01fc1ccddbab",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "005710cb28947926",
        "hash_cont_tokens": "7c20a3f6e5a5e58a"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_de|0": {
      "hashes": {
        "hash_examples": "82f729c52bea2d22",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "6ee5c1b121690d00",
        "hash_cont_tokens": "d8755dfdfa09f9a1"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:it_de|0": {
      "hashes": {
        "hash_examples": "aa127a747078d118",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "f98ac6770246028c",
        "hash_cont_tokens": "5b9df74e30ecf23c"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_fr|0": {
      "hashes": {
        "hash_examples": "df93c7b6eee9775c",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "615da813a6431415",
        "hash_cont_tokens": "ee6ff43882336892"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_it|0": {
      "hashes": {
        "hash_examples": "ca4af939c99421ed",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "7fd9b8323b529819",
        "hash_cont_tokens": "966aeb57d98d2ea9"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:it_it|0": {
      "hashes": {
        "hash_examples": "1283225273f183c5",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "b386ca226c5c7c6f",
        "hash_cont_tokens": "ac1ef03f3ec7ecb3"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_de|0": {
      "hashes": {
        "hash_examples": "5712a1f521ca0984",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "4b31c3347666af64",
        "hash_cont_tokens": "03ed13f8cf9915f2"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_it|0": {
      "hashes": {
        "hash_examples": "8ae552be61473db8",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "d4f7bfe5fb38b628",
        "hash_cont_tokens": "109280bd871f4d51"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_fr|0": {
      "hashes": {
        "hash_examples": "2789212d8ee281ea",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "ab8d9d65c56f2f62",
        "hash_cont_tokens": "800548fd0538771a"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    }
  },
  "summary_general": {
    "hashes": {
      "hash_examples": "e31e497cb001a9c8",
      "hash_full_prompts": "36ab1e8e1061f5c1",
      "hash_input_tokens": "9d2692393928fc22",
      "hash_cont_tokens": "20fb6bae789040e2"
    },
    "truncated": 0,
    "non_truncated": 0,
    "padded": 0,
    "non_padded": 0
  }
}