{
  "config_general": {
    "lighteval_sha": "?",
    "num_fewshot_seeds": 1,
    "max_samples": null,
    "job_id": "0",
    "start_time": 189130.176089572,
    "end_time": 191076.119280108,
    "total_evaluation_time_secondes": "1945.943190535996",
    "model_config": {
      "model_name": "/users/jmirlach/scratch/apertus-finetuning-lsai/evaluation/merged_model",
      "generation_parameters": {
        "num_blocks": null,
        "block_size": null,
        "early_stopping": null,
        "repetition_penalty": 1.05,
        "frequency_penalty": null,
        "length_penalty": null,
        "presence_penalty": null,
        "max_new_tokens": null,
        "min_new_tokens": null,
        "seed": 2025,
        "stop_tokens": null,
        "temperature": 0.7,
        "top_k": 20,
        "min_p": null,
        "top_p": 0.8,
        "truncate_prompt": null,
        "cache_implementation": null,
        "response_format": null
      },
      "system_prompt": "You are a legal expert specializing in Swiss Federal Supreme Court decisions with extensive knowledge of legal terminology and conventions in German, French, and Italian. Your task is to generate a headnote for a provided leading decision. A headnote is a concise summary that captures the key legal points and significance of the decision. It is not merely a summary of the content but highlights the aspects that make the decision \"leading\" and important for future legislation.\n\nWhen generating the headnote:\n\n1. Focus on the core legal reasoning and key considerations that establish the decision's significance.\n2. Include any relevant references to legal articles (prefixed with \"Art.\") and considerations (prefixed with \"E.\" in German or \"consid.\" in French/Italian).\n3. Use precise legal terminology and adhere to the formal and professional style typical of Swiss Federal Supreme Court headnotes.\n4. Ensure clarity and coherence, so the headnote is logically structured and easy to understand in the specified language.\n\nYour response should consist solely of the headnote in the language specified by the user prompt.",
      "cache_dir": "~/.cache/huggingface/lighteval",
      "tokenizer": null,
      "revision": "main",
      "dtype": "bfloat16",
      "tensor_parallel_size": 4,
      "data_parallel_size": 1,
      "pipeline_parallel_size": 1,
      "gpu_memory_utilization": 0.7,
      "enable_prefix_caching": false,
      "max_model_length": 8192,
      "quantization": null,
      "load_format": null,
      "swap_space": 8,
      "seed": 2025,
      "trust_remote_code": true,
      "add_special_tokens": true,
      "multichoice_continuations_start_space": true,
      "pairwise_tokenization": false,
      "max_num_seqs": 64,
      "max_num_batched_tokens": 2048,
      "subfolder": null,
      "is_async": false,
      "override_chat_template": null
    },
    "model_name": "/users/jmirlach/scratch/apertus-finetuning-lsai/evaluation/merged_model"
  },
  "results": {
    "slds:it_de|1": {
      "slds_judge": 10.833333333333334,
      "slds_judge_stderr": 2.8757958933488346,
      "BERTScore-P": 12.323576017903784,
      "BERTScore-P_stderr": 5.376101134970173,
      "BERTScore-R": 5.705716418257604,
      "BERTScore-R_stderr": 4.504998039767421,
      "BERTScore-F": 9.000358320675636,
      "BERTScore-F_stderr": 2.5700041513934564,
      "bleu": 11.734577789202575,
      "bleu_stderr": 0.05340087493263044,
      "rouge1": 0.2931864382293942,
      "rouge1_stderr": 0.02736171028339091,
      "rouge2": 0.11100359732022701,
      "rouge2_stderr": 0.02180687472985111,
      "rougeL": 0.1851756628644822,
      "rougeL_stderr": 0.01993199259625233,
      "summarization_coverage": 0.42067728331774007,
      "summarization_coverage_stderr": 0.04037767984443937,
      "summarization_density": 0.7618592812061887,
      "summarization_density_stderr": 0.09765672635180467,
      "summarization_compression": 54.7701296704669,
      "summarization_compression_stderr": 10.905372729436143
    },
    "slds:de_fr|1": {
      "slds_judge": 18.695652173913043,
      "slds_judge_stderr": 1.2678797343782142,
      "BERTScore-P": 34.18144580867627,
      "BERTScore-P_stderr": 1.1484004272924957,
      "BERTScore-R": 23.831890533781714,
      "BERTScore-R_stderr": 1.2458737710489298,
      "BERTScore-F": 28.998734318574773,
      "BERTScore-F_stderr": 0.9302900663895342,
      "bleu": 11.8349035519766,
      "bleu_stderr": 0.015384570700117176,
      "rouge1": 0.37720366853409193,
      "rouge1_stderr": 0.006839352605792279,
      "rouge2": 0.15347531527878908,
      "rouge2_stderr": 0.004820927594216475,
      "rougeL": 0.24279214451514425,
      "rougeL_stderr": 0.00510126852788729,
      "summarization_coverage": 0.3580188089702041,
      "summarization_coverage_stderr": 0.008026365525740943,
      "summarization_density": 0.6852128184078892,
      "summarization_density_stderr": 0.02243327183284723,
      "summarization_compression": 37.70287839877349,
      "summarization_compression_stderr": 1.820649616676053
    },
    "slds:it_fr|1": {
      "slds_judge": 27.5,
      "slds_judge_stderr": 6.41080999940607,
      "BERTScore-P": 22.693227184936404,
      "BERTScore-P_stderr": 8.68697660779154,
      "BERTScore-R": 22.895006990681093,
      "BERTScore-R_stderr": 4.562342847154506,
      "BERTScore-F": 22.754209775788087,
      "BERTScore-F_stderr": 4.658655374389367,
      "bleu": 12.638979248207294,
      "bleu_stderr": 0.07195745214124394,
      "rouge1": 0.33452478067927965,
      "rouge1_stderr": 0.03930856718360296,
      "rouge2": 0.15488031928841278,
      "rouge2_stderr": 0.02887903245304271,
      "rougeL": 0.2052002627555477,
      "rougeL_stderr": 0.028492162990027346,
      "summarization_coverage": 0.48423266565324025,
      "summarization_coverage_stderr": 0.026315694550298897,
      "summarization_density": 0.9047295549606909,
      "summarization_density_stderr": 0.08734167760224368,
      "summarization_compression": 34.928801827942856,
      "summarization_compression_stderr": 4.973430740555148
    },
    "slds:fr_de|1": {
      "slds_judge": 12.05607476635514,
      "slds_judge_stderr": 1.7753296626220947,
      "BERTScore-P": 19.66821287288635,
      "BERTScore-P_stderr": 1.9996522030264963,
      "BERTScore-R": 7.381127671138427,
      "BERTScore-R_stderr": 1.7326236124830432,
      "BERTScore-F": 13.518050358038849,
      "BERTScore-F_stderr": 1.5344784155323905,
      "bleu": 11.047142552760654,
      "bleu_stderr": 0.02120312948168894,
      "rouge1": 0.3046726310732665,
      "rouge1_stderr": 0.008047715125321932,
      "rouge2": 0.10879835132546524,
      "rouge2_stderr": 0.006658406063484232,
      "rougeL": 0.2062576220889526,
      "rougeL_stderr": 0.006382054675027545,
      "summarization_coverage": 0.436623452124853,
      "summarization_coverage_stderr": 0.01261264466052785,
      "summarization_density": 2.811157718136861,
      "summarization_density_stderr": 1.6828165499753889,
      "summarization_compression": 53.974244126248294,
      "summarization_compression_stderr": 3.7151230839858185
    },
    "slds:de_it|1": {
      "slds_judge": 13.816425120772946,
      "slds_judge_stderr": 1.0530355298306524,
      "BERTScore-P": 31.264127032147442,
      "BERTScore-P_stderr": 1.2507136323951777,
      "BERTScore-R": 22.395557711088742,
      "BERTScore-R_stderr": 1.3457007393805864,
      "BERTScore-F": 26.82630823885805,
      "BERTScore-F_stderr": 1.0877252520082192,
      "bleu": 11.408939782215802,
      "bleu_stderr": 0.014796891889095084,
      "rouge1": 0.3330741454096152,
      "rouge1_stderr": 0.006561071378872954,
      "rouge2": 0.12816896574561615,
      "rouge2_stderr": 0.004621203700359139,
      "rougeL": 0.22261506864121045,
      "rougeL_stderr": 0.005132565984045911,
      "summarization_coverage": 0.31331713956008245,
      "summarization_coverage_stderr": 0.006814452120399819,
      "summarization_density": 0.4912788651252765,
      "summarization_density_stderr": 0.013170670739905549,
      "summarization_compression": 39.76198674131042,
      "summarization_compression_stderr": 2.6646459929825212
    },
    "slds:de_de|1": {
      "slds_judge": 20.0,
      "slds_judge_stderr": 1.374829169752226,
      "BERTScore-P": 29.029910277127026,
      "BERTScore-P_stderr": 1.9349133518859651,
      "BERTScore-R": 18.736595256382866,
      "BERTScore-R_stderr": 1.4550672438930703,
      "BERTScore-F": 23.864054572566047,
      "BERTScore-F_stderr": 1.4250685123796694,
      "bleu": 15.996309292190006,
      "bleu_stderr": 0.023153814459576715,
      "rouge1": 0.36379948664127526,
      "rouge1_stderr": 0.008816385834504812,
      "rouge2": 0.17915194729508133,
      "rouge2_stderr": 0.008163485490769918,
      "rougeL": 0.26407954227343494,
      "rougeL_stderr": 0.008029444851622299,
      "summarization_coverage": 0.9291437040950409,
      "summarization_coverage_stderr": 0.006376046123567221,
      "summarization_density": 8.839901512223848,
      "summarization_density_stderr": 0.7335172956374528,
      "summarization_compression": 47.3649629156694,
      "summarization_compression_stderr": 2.89962564537671
    },
    "slds:fr_fr|1": {
      "slds_judge": 20.093457943925234,
      "slds_judge_stderr": 1.8708773620242611,
      "BERTScore-P": 37.36165312823848,
      "BERTScore-P_stderr": 2.462467756531781,
      "BERTScore-R": 25.104655720966445,
      "BERTScore-R_stderr": 1.8208452777266309,
      "BERTScore-F": 31.20648458112623,
      "BERTScore-F_stderr": 1.7075688222925345,
      "bleu": 16.451244673880865,
      "bleu_stderr": 0.030703816693132543,
      "rouge1": 0.4023803289432808,
      "rouge1_stderr": 0.0111621993442685,
      "rouge2": 0.20544552717420556,
      "rouge2_stderr": 0.01006737730976816,
      "rougeL": 0.2709540154390743,
      "rougeL_stderr": 0.009164358145430717,
      "summarization_coverage": 0.9386739375002411,
      "summarization_coverage_stderr": 0.008102475402500302,
      "summarization_density": 10.91297109223509,
      "summarization_density_stderr": 1.3567319722131248,
      "summarization_compression": 46.90958390370706,
      "summarization_compression_stderr": 4.412828973911151
    },
    "slds:it_it|1": {
      "slds_judge": 16.666666666666668,
      "slds_judge_stderr": 4.3228310962688195,
      "BERTScore-P": 28.52043639868498,
      "BERTScore-P_stderr": 8.60458352117755,
      "BERTScore-R": 20.885315009703238,
      "BERTScore-R_stderr": 5.685255359703131,
      "BERTScore-F": 24.674771167337894,
      "BERTScore-F_stderr": 5.798276660169933,
      "bleu": 13.273382551906305,
      "bleu_stderr": 0.08586810826794866,
      "rouge1": 0.3094691191977879,
      "rouge1_stderr": 0.0334609558699857,
      "rouge2": 0.16554900030003875,
      "rouge2_stderr": 0.03338396545080639,
      "rougeL": 0.22251428347744853,
      "rougeL_stderr": 0.02689440801426075,
      "summarization_coverage": 0.9711536866640826,
      "summarization_coverage_stderr": 0.005648738453714132,
      "summarization_density": 15.585964757931308,
      "summarization_density_stderr": 7.9228948016398295,
      "summarization_compression": 55.74246085907894,
      "summarization_compression_stderr": 11.965734273111197
    },
    "slds:fr_it|1": {
      "slds_judge": 14.018691588785046,
      "slds_judge_stderr": 1.495657695777924,
      "BERTScore-P": 33.462857681317864,
      "BERTScore-P_stderr": 1.6855393497767865,
      "BERTScore-R": 22.00309663424029,
      "BERTScore-R_stderr": 1.6515973828751278,
      "BERTScore-F": 27.720884967456076,
      "BERTScore-F_stderr": 1.2639997891531218,
      "bleu": 10.90649913327479,
      "bleu_stderr": 0.02371352980486446,
      "rouge1": 0.334579792856031,
      "rouge1_stderr": 0.008848299139944123,
      "rouge2": 0.13712384258902405,
      "rouge2_stderr": 0.006942436017927557,
      "rougeL": 0.2249185760725875,
      "rougeL_stderr": 0.006503194907523754,
      "summarization_coverage": 0.4003884132105528,
      "summarization_coverage_stderr": 0.009499183596450009,
      "summarization_density": 1.0432933287859334,
      "summarization_density_stderr": 0.247342754214638,
      "summarization_compression": 52.30008002746624,
      "summarization_compression_stderr": 3.7063176873571617
    },
    "slds:_average|1": {
      "slds_judge": 17.07558906597238,
      "slds_judge_stderr": 2.4941162381565665,
      "BERTScore-P": 27.611716266879842,
      "BERTScore-P_stderr": 3.6832608872053294,
      "BERTScore-R": 18.770995771804493,
      "BERTScore-R_stderr": 2.6671449193369385,
      "BERTScore-F": 23.17376181115796,
      "BERTScore-F_stderr": 2.3306741159675806,
      "bleu": 12.810219841734988,
      "bleu_stderr": 0.03779802093003311,
      "rouge1": 0.33921004350711365,
      "rouge1_stderr": 0.01671180630729824,
      "rouge2": 0.1492885407018733,
      "rouge2_stderr": 0.013927078756691743,
      "rougeL": 0.2271674642364314,
      "rougeL_stderr": 0.012847938965786438,
      "summarization_coverage": 0.5835810101217819,
      "summarization_coverage_stderr": 0.013752586697515395,
      "summarization_density": 4.670707658779232,
      "summarization_density_stderr": 1.3515450800230262,
      "summarization_compression": 47.05056983007374,
      "summarization_compression_stderr": 5.229303193710212
    },
    "all": {
      "slds_judge": 17.075589065972377,
      "slds_judge_stderr": 2.4941162381565665,
      "BERTScore-P": 27.611716266879846,
      "BERTScore-P_stderr": 3.6832608872053303,
      "BERTScore-R": 18.770995771804493,
      "BERTScore-R_stderr": 2.6671449193369385,
      "BERTScore-F": 23.17376181115796,
      "BERTScore-F_stderr": 2.3306741159675806,
      "bleu": 12.81021984173499,
      "bleu_stderr": 0.03779802093003311,
      "rouge1": 0.33921004350711365,
      "rouge1_stderr": 0.01671180630729824,
      "rouge2": 0.1492885407018733,
      "rouge2_stderr": 0.013927078756691743,
      "rougeL": 0.2271674642364314,
      "rougeL_stderr": 0.012847938965786438,
      "summarization_coverage": 0.5835810101217819,
      "summarization_coverage_stderr": 0.013752586697515395,
      "summarization_density": 4.670707658779232,
      "summarization_density_stderr": 1.351545080023026,
      "summarization_compression": 47.05056983007374,
      "summarization_compression_stderr": 5.229303193710212
    }
  },
  "versions": {},
  "config_tasks": {
    "slds:it_de|1": {
      "name": "slds:it_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x400601d83530>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400601d83b90>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400601d830b0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400601d81bb0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x400601d81820>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:de_fr|1": {
      "name": "slds:de_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4004d43fad50>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d43fbe30>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d43f85c0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d43fb6e0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4004d43fa1e0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:it_fr|1": {
      "name": "slds:it_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4004d5fbcda0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d5fbdac0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d5fbfda0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d5fbfcb0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4004d5fbf9e0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:fr_de|1": {
      "name": "slds:fr_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4004d7cd38c0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d7cd3590>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d7cd33b0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400609ed1970>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x400609ed12b0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:de_it|1": {
      "name": "slds:de_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4004d4040d70>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d007aff0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d00f1970>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004d4040ef0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4004d4040ec0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:de_de|1": {
      "name": "slds:de_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x40009cdb1dc0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40009cdb2000>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40009cdb1fd0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40009cdb1f40>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40009cdb1f10>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:fr_fr|1": {
      "name": "slds:fr_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4005bcd77470>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4005bcd77560>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4005bcd775c0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4005bcd77650>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4005bcd77350>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:it_it|1": {
      "name": "slds:it_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x40061a8a7f50>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40061a8a7ad0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40061a8a79e0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40061a8a7bf0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40061a8a7e90>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:fr_it|1": {
      "name": "slds:fr_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x40061bcc4ef0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40061bcc4fb0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40061bcc5010>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40061bcc4fe0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-v3.2, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40061bcc4e60>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    }
  },
  "summary_tasks": {
    "slds:it_de|1": {
      "hashes": {
        "hash_examples": "aa127a747078d118",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "13ac92a41287cb23",
        "hash_cont_tokens": "2758f0baec7c2072"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_fr|1": {
      "hashes": {
        "hash_examples": "2789212d8ee281ea",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "7ba74735e892810d",
        "hash_cont_tokens": "11b3b2a858848532"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:it_fr|1": {
      "hashes": {
        "hash_examples": "738c01fc1ccddbab",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "eade19bcdd16db08",
        "hash_cont_tokens": "4d5a2387a448169a"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_de|1": {
      "hashes": {
        "hash_examples": "82f729c52bea2d22",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "1f559164bd3fe8fc",
        "hash_cont_tokens": "2fd2d222a6116724"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_it|1": {
      "hashes": {
        "hash_examples": "8ae552be61473db8",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "9c894ba83e6d97e6",
        "hash_cont_tokens": "da63320456e3c238"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_de|1": {
      "hashes": {
        "hash_examples": "5712a1f521ca0984",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "5e7d03d6a14f5a72",
        "hash_cont_tokens": "7d6a6f39f594886e"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_fr|1": {
      "hashes": {
        "hash_examples": "df93c7b6eee9775c",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "1a1508209a0d1c80",
        "hash_cont_tokens": "0dc68a1108609331"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:it_it|1": {
      "hashes": {
        "hash_examples": "1283225273f183c5",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "3d3f13f6928643cb",
        "hash_cont_tokens": "e33165b208e95b85"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_it|1": {
      "hashes": {
        "hash_examples": "ca4af939c99421ed",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "2719b562cfa1336e",
        "hash_cont_tokens": "db92319018d1b67f"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    }
  },
  "summary_general": {
    "hashes": {
      "hash_examples": "e31e497cb001a9c8",
      "hash_full_prompts": "36ab1e8e1061f5c1",
      "hash_input_tokens": "4c5f732c1e541737",
      "hash_cont_tokens": "b0575a2ad68a7a9b"
    },
    "truncated": 0,
    "non_truncated": 0,
    "padded": 0,
    "non_padded": 0
  }
}