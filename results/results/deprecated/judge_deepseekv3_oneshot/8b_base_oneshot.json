{
  "config_general": {
    "lighteval_sha": "?",
    "num_fewshot_seeds": 1,
    "max_samples": null,
    "job_id": "0",
    "start_time": 197617.990221713,
    "end_time": 198980.861100267,
    "total_evaluation_time_secondes": "1362.8708785540075",
    "model_config": {
      "model_name": "swiss-ai/Apertus-8B-Instruct-2509",
      "generation_parameters": {
        "num_blocks": null,
        "block_size": null,
        "early_stopping": null,
        "repetition_penalty": 1.05,
        "frequency_penalty": null,
        "length_penalty": null,
        "presence_penalty": null,
        "max_new_tokens": null,
        "min_new_tokens": null,
        "seed": 2025,
        "stop_tokens": null,
        "temperature": 0.7,
        "top_k": 20,
        "min_p": null,
        "top_p": 0.8,
        "truncate_prompt": null,
        "cache_implementation": null,
        "response_format": null
      },
      "system_prompt": "You are a legal expert specializing in Swiss Federal Supreme Court decisions with extensive knowledge of legal terminology and conventions in German, French, and Italian. Your task is to generate a headnote for a provided leading decision. A headnote is a concise summary that captures the key legal points and significance of the decision. It is not merely a summary of the content but highlights the aspects that make the decision \"leading\" and important for future legislation.\n\nWhen generating the headnote:\n\n1. Focus on the core legal reasoning and key considerations that establish the decision's significance.\n2. Include any relevant references to legal articles (prefixed with \"Art.\") and considerations (prefixed with \"E.\" in German or \"consid.\" in French/Italian).\n3. Use precise legal terminology and adhere to the formal and professional style typical of Swiss Federal Supreme Court headnotes.\n4. Ensure clarity and coherence, so the headnote is logically structured and easy to understand in the specified language.\n\nYour response should consist solely of the headnote in the language specified by the user prompt.",
      "cache_dir": "~/.cache/huggingface/lighteval",
      "tokenizer": null,
      "revision": "main",
      "dtype": "bfloat16",
      "tensor_parallel_size": 4,
      "data_parallel_size": 1,
      "pipeline_parallel_size": 1,
      "gpu_memory_utilization": 0.7,
      "enable_prefix_caching": false,
      "max_model_length": 8192,
      "quantization": null,
      "load_format": null,
      "swap_space": 8,
      "seed": 2025,
      "trust_remote_code": true,
      "add_special_tokens": true,
      "multichoice_continuations_start_space": true,
      "pairwise_tokenization": false,
      "max_num_seqs": 64,
      "max_num_batched_tokens": 2048,
      "subfolder": null,
      "is_async": false,
      "override_chat_template": null
    },
    "model_name": "swiss-ai/Apertus-8B-Instruct-2509"
  },
  "results": {
    "slds:it_fr|1": {
      "slds_judge": 32.5,
      "slds_judge_stderr": 4.459412925079223,
      "BERTScore-P": 21.732260566204786,
      "BERTScore-P_stderr": 5.841105614604128,
      "BERTScore-R": 15.206603263504803,
      "BERTScore-R_stderr": 4.912851513119456,
      "BERTScore-F": 18.468382333715756,
      "BERTScore-F_stderr": 4.313321494492443,
      "bleu": 9.64551352010752,
      "bleu_stderr": 0.07887236626212035,
      "rouge1": 0.3483195347864543,
      "rouge1_stderr": 0.03752124983329617,
      "rouge2": 0.13950330212684,
      "rouge2_stderr": 0.02094489447600822,
      "rougeL": 0.20043309777471952,
      "rougeL_stderr": 0.01924805425861327,
      "summarization_coverage": 0.41772603484770715,
      "summarization_coverage_stderr": 0.035783555996708315,
      "summarization_density": 0.7285310900150038,
      "summarization_density_stderr": 0.11104265787896102,
      "summarization_compression": 56.80780934463629,
      "summarization_compression_stderr": 19.081830922389603
    },
    "slds:fr_fr|1": {
      "slds_judge": 33.36448598130841,
      "slds_judge_stderr": 1.5820805149115935,
      "BERTScore-P": 32.11300153019795,
      "BERTScore-P_stderr": 1.9141357126090202,
      "BERTScore-R": 25.390212254481234,
      "BERTScore-R_stderr": 1.8048697496659725,
      "BERTScore-F": 28.745569180366452,
      "BERTScore-F_stderr": 1.5152676890320222,
      "bleu": 13.382721779674943,
      "bleu_stderr": 0.028886617461374227,
      "rouge1": 0.4169668473647912,
      "rouge1_stderr": 0.010343857490362313,
      "rouge2": 0.21040967176921846,
      "rouge2_stderr": 0.00878466302827732,
      "rougeL": 0.2609214785680505,
      "rougeL_stderr": 0.007517939430673074,
      "summarization_coverage": 0.9173011907783308,
      "summarization_coverage_stderr": 0.005385510160699374,
      "summarization_density": 4.936565474761307,
      "summarization_density_stderr": 0.4421145655861861,
      "summarization_compression": 41.29989585856215,
      "summarization_compression_stderr": 2.4184041460162384
    },
    "slds:de_de|1": {
      "slds_judge": 29.468599033816425,
      "slds_judge_stderr": 1.2312240327685446,
      "BERTScore-P": 19.91745356834777,
      "BERTScore-P_stderr": 1.5258755167440157,
      "BERTScore-R": 19.254909309779027,
      "BERTScore-R_stderr": 1.4594069786478412,
      "BERTScore-F": 19.585023485214094,
      "BERTScore-F_stderr": 1.2740471593842226,
      "bleu": 12.114917626989339,
      "bleu_stderr": 0.023813567578725377,
      "rouge1": 0.3334867637050672,
      "rouge1_stderr": 0.008221790192286724,
      "rouge2": 0.1430295810069493,
      "rouge2_stderr": 0.007873733688693962,
      "rougeL": 0.21803262943049373,
      "rougeL_stderr": 0.0073306294893561875,
      "summarization_coverage": 0.9076760239680874,
      "summarization_coverage_stderr": 0.004027557808276094,
      "summarization_density": 5.670843502199902,
      "summarization_density_stderr": 0.46270218983813777,
      "summarization_compression": 41.18733461462772,
      "summarization_compression_stderr": 2.7583424436783046
    },
    "slds:it_it|1": {
      "slds_judge": 30.0,
      "slds_judge_stderr": 4.438126822992973,
      "BERTScore-P": 25.66878426199158,
      "BERTScore-P_stderr": 6.080489346982137,
      "BERTScore-R": 19.568094626689952,
      "BERTScore-R_stderr": 5.052923717147098,
      "BERTScore-F": 22.611817096670467,
      "BERTScore-F_stderr": 4.374826424646779,
      "bleu": 12.442727071475742,
      "bleu_stderr": 0.06820385180226776,
      "rouge1": 0.3252510848606943,
      "rouge1_stderr": 0.040926420589415535,
      "rouge2": 0.15040266809084937,
      "rouge2_stderr": 0.029222636746345308,
      "rougeL": 0.2022068295866365,
      "rougeL_stderr": 0.028022133466633032,
      "summarization_coverage": 0.9077971087727366,
      "summarization_coverage_stderr": 0.018039368666253504,
      "summarization_density": 4.926185138885777,
      "summarization_density_stderr": 0.8267966310069399,
      "summarization_compression": 44.32693462375795,
      "summarization_compression_stderr": 9.696923739958455
    },
    "slds:it_de|1": {
      "slds_judge": 24.166666666666668,
      "slds_judge_stderr": 5.1431527492405085,
      "BERTScore-P": -2.203438555200895,
      "BERTScore-P_stderr": 4.074077591861268,
      "BERTScore-R": 3.6545187855760255,
      "BERTScore-R_stderr": 3.8224639918535046,
      "BERTScore-F": 0.727609257834653,
      "BERTScore-F_stderr": 1.966093512027745,
      "bleu": 6.928040103160049,
      "bleu_stderr": 0.04473546201830824,
      "rouge1": 0.26174104723528485,
      "rouge1_stderr": 0.029827105704567963,
      "rouge2": 0.07096947454717578,
      "rouge2_stderr": 0.012607399030318062,
      "rougeL": 0.144738222633479,
      "rougeL_stderr": 0.014684032947062567,
      "summarization_coverage": 0.32069500375116244,
      "summarization_coverage_stderr": 0.03464460431500344,
      "summarization_density": 0.45195134186537683,
      "summarization_density_stderr": 0.06599457551410208,
      "summarization_compression": 50.60462106038583,
      "summarization_compression_stderr": 15.98379581336974
    },
    "slds:fr_it|1": {
      "slds_judge": 23.64485981308411,
      "slds_judge_stderr": 1.5565093229781273,
      "BERTScore-P": 22.61919468297475,
      "BERTScore-P_stderr": 1.8682626678175007,
      "BERTScore-R": 17.20841962356712,
      "BERTScore-R_stderr": 1.773650714428338,
      "BERTScore-F": 19.917154745032867,
      "BERTScore-F_stderr": 1.5478436106381763,
      "bleu": 8.337238827402246,
      "bleu_stderr": 0.02209421374623157,
      "rouge1": 0.3108118759247424,
      "rouge1_stderr": 0.009839704017150773,
      "rouge2": 0.1083410467597268,
      "rouge2_stderr": 0.006447231266139706,
      "rougeL": 0.18409024196644508,
      "rougeL_stderr": 0.006346180199675657,
      "summarization_coverage": 0.303455759426214,
      "summarization_coverage_stderr": 0.012488606921179191,
      "summarization_density": 0.5792728303421601,
      "summarization_density_stderr": 0.06443117654341579,
      "summarization_compression": 38.63255082675909,
      "summarization_compression_stderr": 2.3503727630351605
    },
    "slds:de_it|1": {
      "slds_judge": 19.71014492753623,
      "slds_judge_stderr": 0.989871893218564,
      "BERTScore-P": 21.443846215975384,
      "BERTScore-P_stderr": 1.1040835819876804,
      "BERTScore-R": 17.759512703199892,
      "BERTScore-R_stderr": 1.1592751992157888,
      "BERTScore-F": 19.60903478489406,
      "BERTScore-F_stderr": 0.9325638225137152,
      "bleu": 6.821948900961793,
      "bleu_stderr": 0.012474673423253266,
      "rouge1": 0.29669632255309775,
      "rouge1_stderr": 0.00576155553914825,
      "rouge2": 0.08955471352364319,
      "rouge2_stderr": 0.0039057540410827396,
      "rougeL": 0.17502212365481098,
      "rougeL_stderr": 0.004285773115824794,
      "summarization_coverage": 0.20219808768935138,
      "summarization_coverage_stderr": 0.0062347398576627555,
      "summarization_density": 0.32221499055968644,
      "summarization_density_stderr": 0.021678763298150813,
      "summarization_compression": 29.258010935552996,
      "summarization_compression_stderr": 1.3144929466296633
    },
    "slds:de_fr|1": {
      "slds_judge": 23.96135265700483,
      "slds_judge_stderr": 1.1857194260138388,
      "BERTScore-P": 21.76046194666142,
      "BERTScore-P_stderr": 1.2397291853223578,
      "BERTScore-R": 18.750240360409165,
      "BERTScore-R_stderr": 1.2249717596279759,
      "BERTScore-F": 20.259450504596792,
      "BERTScore-F_stderr": 1.0249588696529734,
      "bleu": 8.088122961445366,
      "bleu_stderr": 0.012552017639312883,
      "rouge1": 0.35562535394381656,
      "rouge1_stderr": 0.006182615879387226,
      "rouge2": 0.12597864174298573,
      "rouge2_stderr": 0.004158617027284715,
      "rougeL": 0.20730538907019544,
      "rougeL_stderr": 0.004006697689397401,
      "summarization_coverage": 0.2599389540733045,
      "summarization_coverage_stderr": 0.00837451130310644,
      "summarization_density": 0.441610059003481,
      "summarization_density_stderr": 0.026483144920353203,
      "summarization_compression": 28.925853035373713,
      "summarization_compression_stderr": 1.0014237129914432
    },
    "slds:fr_de|1": {
      "slds_judge": 23.64485981308411,
      "slds_judge_stderr": 1.5565093229781273,
      "BERTScore-P": 8.258303204142253,
      "BERTScore-P_stderr": 2.1815022669634776,
      "BERTScore-R": 2.7436204306850924,
      "BERTScore-R_stderr": 1.9249145339257479,
      "BERTScore-F": 5.494496577079887,
      "BERTScore-F_stderr": 1.6362502989873113,
      "bleu": 7.521792481107829,
      "bleu_stderr": 0.021926492901694187,
      "rouge1": 0.27048984760109906,
      "rouge1_stderr": 0.008666177126606629,
      "rouge2": 0.08362403632127752,
      "rouge2_stderr": 0.005743991219463577,
      "rougeL": 0.1650413601308467,
      "rougeL_stderr": 0.005991115849851217,
      "summarization_coverage": 0.3124437392166142,
      "summarization_coverage_stderr": 0.013621437273218956,
      "summarization_density": 1.711380337057294,
      "summarization_density_stderr": 1.1731335085952674,
      "summarization_compression": 48.549517554358395,
      "summarization_compression_stderr": 3.70496455379893
    },
    "slds:_average|1": {
      "slds_judge": 26.717885432500086,
      "slds_judge_stderr": 2.4602896677979444,
      "BERTScore-P": 19.034429713477223,
      "BERTScore-P_stderr": 2.8699179427657318,
      "BERTScore-R": 15.504014595321369,
      "BERTScore-R_stderr": 2.570592017514636,
      "BERTScore-F": 17.26872644060056,
      "BERTScore-F_stderr": 2.0650192090417097,
      "bleu": 9.475891474702758,
      "bleu_stderr": 0.034839918092587546,
      "rouge1": 0.32437651977500526,
      "rouge1_stderr": 0.017476719596913506,
      "rouge2": 0.12464590398762956,
      "rouge2_stderr": 0.011076546724845957,
      "rougeL": 0.19531015253507525,
      "rougeL_stderr": 0.010825839605231912,
      "summarization_coverage": 0.505470211391501,
      "summarization_coverage_stderr": 0.015399988033567562,
      "summarization_density": 2.196506084965554,
      "summarization_density_stderr": 0.35493080146461264,
      "summarization_compression": 42.176947539334904,
      "summarization_compression_stderr": 6.47895011576306
    },
    "all": {
      "slds_judge": 26.717885432500083,
      "slds_judge_stderr": 2.4602896677979444,
      "BERTScore-P": 19.034429713477223,
      "BERTScore-P_stderr": 2.8699179427657318,
      "BERTScore-R": 15.504014595321369,
      "BERTScore-R_stderr": 2.570592017514636,
      "BERTScore-F": 17.26872644060056,
      "BERTScore-F_stderr": 2.0650192090417097,
      "bleu": 9.475891474702758,
      "bleu_stderr": 0.034839918092587546,
      "rouge1": 0.32437651977500526,
      "rouge1_stderr": 0.01747671959691351,
      "rouge2": 0.12464590398762956,
      "rouge2_stderr": 0.011076546724845959,
      "rougeL": 0.19531015253507525,
      "rougeL_stderr": 0.010825839605231913,
      "summarization_coverage": 0.505470211391501,
      "summarization_coverage_stderr": 0.015399988033567562,
      "summarization_density": 2.196506084965554,
      "summarization_density_stderr": 0.3549308014646127,
      "summarization_compression": 42.176947539334904,
      "summarization_compression_stderr": 6.47895011576306
    }
  },
  "versions": {},
  "config_tasks": {
    "slds:it_fr|1": {
      "name": "slds:it_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4005d97fad80>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4005d97fa270>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4005d97fbfb0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4005d97faa50>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4005d97f9b20>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:fr_fr|1": {
      "name": "slds:fr_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4004f5885eb0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004f5887b60>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004f5887da0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004e01a1940>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4004e01a3fe0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:de_de|1": {
      "name": "slds:de_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x4004f88a9f10>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004f88a9430>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004f88a9790>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x4004f88a8110>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x4004f88a83b0>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:it_it|1": {
      "name": "slds:it_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x40062b8dd940>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40062b91c710>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40062b91d520>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40062b8dd7f0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40062b8ddb80>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:it_de|1": {
      "name": "slds:it_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "it_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x40062bcff320>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40062bcff5f0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40062bcff620>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40062bcff5c0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40062bcff560>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:fr_it|1": {
      "name": "slds:fr_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x400638f529f0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400638f52840>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400638f52810>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400638f52870>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x400638f52b40>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:de_it|1": {
      "name": "slds:de_it",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_it",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x40063a3463f0>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=it, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40063a3465d0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40063a346660>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x40063a346570>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=it, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x40063a346690>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=it)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:de_fr|1": {
      "name": "slds:de_fr",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "de_fr",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x400800b67b00>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=fr, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400800b67d40>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400800b67980>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400800b67d10>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=fr, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x400800b67c50>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=fr)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    },
    "slds:fr_de|1": {
      "name": "slds:fr_de",
      "prompt_function": "slds_prompt_fn",
      "hf_repo": "ipst/slds",
      "hf_subset": "fr_de",
      "metrics": [
        {
          "metric_name": [
            "BERTScore-P",
            "BERTScore-R",
            "BERTScore-F"
          ],
          "higher_is_better": {
            "BERTScore-P": true,
            "BERTScore-R": true,
            "BERTScore-F": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "BertScoreMultilingual(bert_scorer=<lighteval.metrics.imports.bert_scorer.BERTScorer object at 0x400800b98c80>, normalize_gold=remove_braces, normalize_pred=remove_braces_and_strip, language=de, model_type=xlm-roberta-large, num_layers=24, device=cuda)",
          "corpus_level_fn": {
            "BERTScore-P": "mean",
            "BERTScore-R": "mean",
            "BERTScore-F": "mean"
          },
          "batched_compute": false
        },
        {
          "metric_name": "bleu",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "GenerativePreparator()",
          "corpus_level_fn": "CorpusLevelTranslationMetric(metric_type=bleu, lang=)",
          "batched_compute": false
        },
        {
          "metric_name": "rouge1",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge1'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400800b98710>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rouge2",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rouge2'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400800b99bb0>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": "rougeL",
          "higher_is_better": true,
          "category": "GENERATIVE",
          "sample_level_fn": "ROUGE(aggregation_function=mean, methods=['rougeL'], multiple_golds=False, bootstrap=False, normalize_gold=None, normalize_pred=None, tokenizer=None, scorer=<rouge_score.rouge_scorer.RougeScorer object at 0x400800b66540>)",
          "corpus_level_fn": "mean",
          "batched_compute": false
        },
        {
          "metric_name": [
            "slds_judge"
          ],
          "higher_is_better": {
            "slds_judge": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "JudgeSwissLandmarkDecisionSummarization(language=de, short_judge_name=slds_judge, judge=Model: openai/deepseek/deepseek-chat, Judge Backend: litellm, URL: None)",
          "corpus_level_fn": {
            "slds_judge": "mean"
          },
          "batched_compute": true
        },
        {
          "metric_name": [
            "summarization_coverage",
            "summarization_density",
            "summarization_compression"
          ],
          "higher_is_better": {
            "summarization_coverage": true,
            "summarization_density": true,
            "summarization_compression": true
          },
          "category": "GENERATIVE",
          "sample_level_fn": "Extractiveness(stats_metric=<lighteval.metrics.imports.data_stats_metric.DataStatsMetric object at 0x400800b64560>, normalize_input=remove_braces, normalize_pred=remove_braces_and_strip, input_column=text, language=de)",
          "corpus_level_fn": {
            "summarization_coverage": "mean",
            "summarization_density": "mean",
            "summarization_compression": "mean"
          },
          "batched_compute": false
        }
      ],
      "solver": null,
      "scorer": null,
      "sample_fields": null,
      "sample_to_fewshot": null,
      "filter": null,
      "hf_revision": null,
      "hf_filter": "filter_dataset",
      "hf_avail_splits": [
        "train",
        "validation",
        "test",
        "one_shot_examples"
      ],
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "one_shot_examples",
      "few_shots_select": "random",
      "generation_size": 512,
      "generation_grammar": null,
      "stop_sequence": [
        "</s>"
      ],
      "num_samples": null,
      "original_num_docs": -1,
      "effective_num_docs": -1,
      "must_remove_duplicate_docs": false,
      "num_fewshots": 1,
      "version": 0
    }
  },
  "summary_tasks": {
    "slds:it_fr|1": {
      "hashes": {
        "hash_examples": "738c01fc1ccddbab",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "eade19bcdd16db08",
        "hash_cont_tokens": "d4c33576bd8e7797"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_fr|1": {
      "hashes": {
        "hash_examples": "df93c7b6eee9775c",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "1a1508209a0d1c80",
        "hash_cont_tokens": "f483be03976513b0"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_de|1": {
      "hashes": {
        "hash_examples": "5712a1f521ca0984",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "5e7d03d6a14f5a72",
        "hash_cont_tokens": "83355f904433e965"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:it_it|1": {
      "hashes": {
        "hash_examples": "1283225273f183c5",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "3d3f13f6928643cb",
        "hash_cont_tokens": "40435f105665ae82"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:it_de|1": {
      "hashes": {
        "hash_examples": "aa127a747078d118",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "13ac92a41287cb23",
        "hash_cont_tokens": "623214a30e0ad3ea"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_it|1": {
      "hashes": {
        "hash_examples": "ca4af939c99421ed",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "2719b562cfa1336e",
        "hash_cont_tokens": "16bcee221a8881fc"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_it|1": {
      "hashes": {
        "hash_examples": "8ae552be61473db8",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "9c894ba83e6d97e6",
        "hash_cont_tokens": "d44051f181aca56d"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:de_fr|1": {
      "hashes": {
        "hash_examples": "2789212d8ee281ea",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "7ba74735e892810d",
        "hash_cont_tokens": "f0a7d3d28480e293"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    },
    "slds:fr_de|1": {
      "hashes": {
        "hash_examples": "82f729c52bea2d22",
        "hash_full_prompts": "ef46db3751d8e999",
        "hash_input_tokens": "1f559164bd3fe8fc",
        "hash_cont_tokens": "2fe802dc6c941f4f"
      },
      "truncated": 0,
      "non_truncated": 0,
      "padded": 0,
      "non_padded": 0
    }
  },
  "summary_general": {
    "hashes": {
      "hash_examples": "e31e497cb001a9c8",
      "hash_full_prompts": "36ab1e8e1061f5c1",
      "hash_input_tokens": "4c5f732c1e541737",
      "hash_cont_tokens": "c39fdc9509938354"
    },
    "truncated": 0,
    "non_truncated": 0,
    "padded": 0,
    "non_padded": 0
  }
}