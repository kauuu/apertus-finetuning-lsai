# Environment Definition File for Apertus Fine-tuning on Clariden
# This EDF uses the NGC PyTorch container with optimizations for multi-node training

image = "nvcr.io/nvidia/pytorch:25.11-py3"


# Mounts
mounts = [
    "/capstor",
    "/iopsstor",
    "/users"
]

writable = true

[annotations]
# Disable AWS OFI NCCL plugin to avoid OFI segfaults
com.hooks.aws_ofi_nccl.enabled = "false"

[env]
# -------------------------------
# NCCL (DO NOT override OFI)
# -------------------------------
NCCL_DEBUG = "INFO"
NCCL_CROSS_NIC = "1"
NCCL_PROTO = "^LL128"
TORCH_NCCL_ASYNC_ERROR_HANDLING = "1"

# Force NCCL to use Socket and disable OFI/IB inside the container
NCCL_NET = "Socket"
NCCL_SOCKET_IFNAME = "hsn"
NCCL_NET_PLUGIN = ""
NCCL_IB_DISABLE = "1"

# -------------------------------
# CUDA / PyTorch
# -------------------------------
TRITON_HOME = "/dev/shm/"
CUDA_CACHE_DISABLE = "1"

# -------------------------------
# MPI (safe default)
# -------------------------------
MPICH_GPU_SUPPORT_ENABLED = "0"

# -------------------------------
# Weights & Biases
# -------------------------------
WANDB_API_KEY = "INSERT-API-KEY"